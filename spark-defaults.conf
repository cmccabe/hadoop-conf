# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:

#spark.master                    spark://a2402.halxg.cloudera.com:7077

spark.eventLog.enabled          true

spark.eventLog.dir              hdfs:///user/cmccabe/eventlog

spark.executor.memory           6g

#spark.local.dir                 /data/1/cmccabe/mr-local,/data/2/cmccabe/mr-local,/data/3/cmccabe/mr-local,/data/4/cmccabe/mr-local,/data/5/cmccabe/mr-local,/data/6/cmccabe/mr-local,/data/7/cmccabe/mr-local,/data/8/cmccabe/mr-local,/data/9/cmccabe/mr-local,/data/10/cmccabe/mr-local

#spark.default.parallelism       8
#
#spark.storage.memoryFraction    0.6
#
#spark.shuffle.memoryFraction    0.3
#
##spark.mesos.coarse

# port for spark history server
spark.history.ui.port 18080

# port for worker
#worker.ui.port 8081

# port for driver
spark.ui.port 4040

# port for the driver to listen on
#spark.driver.port 7077

##spark.ui.retainedStages
##spark.shuffle.compress
##spark.shuffle.spill.compress
##spark.broadcast.compress
##spark.rdd.compress
##spark.io.compression.codec
##LZFCompressionCodec
##spark.io.compression.snappy.block.size
#
## Is this relevant to YARN?
##spark.scheduler.mode
#
## Fixed memory overhead per task
##spark.reducer.maxMbInFlight     48
#
## Serializer class used for closures
##spark.closure.serializer
#
## Breaks serializing loops to gain speed (wtf?)
##spark.kryo.referenceTracking    true
#
## max object size for Kryo
#spark.kryoserializer.buffer.mb  2
#
#spark.broadcast.factory         org.apache.spark.broadcast.HttpBroadcastFactory
#
#spark.locality.wait             3000
#
#spark.locality.wait.process     spark.locality.wait
#
#spark.locality.wait.node        spark.locality.wait
#
#spark.locality.wait.rack        spark.locality.wait
#
## timeout in seconds for standalone master timing out workers
#spark.worker.timeout            60
#
## maximum message size to allow in control plane communication.  Might need to increase for collect() on a large dataset.
#spark.akka.frameSize            10
#
## Number of actor threads to use for Akka communication.
#spark.akka.threads              4
#
## Akka timeout in seconds.
#spark.akka.timeout              100
#
## This is set to a large value to essentially disable the Akka failure detector.
#spark.akka.heartbeat.pauses     600
#
## ditto
#spark.akka.failure-detector.threshold       300
#
## ditto
#spark.akka.heartbeat.interval   1000
#
## hostname for the driver to listen on#
##spark.driver.host
#
## this is sort of the RDD garbage collection... or something#
##spark.cleaner.ttl              (infinite)
#
#spark.streaming.blockInterval   200
#
#spark.streaming.unpersist       false
#
## Is this relevant for YARN?  I would guess no...
#spark.task.maxFailures          4
#
## Size of each piece of a block in KB for TorrentBroadcastFactory
#spark.broadcast.blockSize       4096
#
## Should we consolidate files created by a shuffle?  Yes (unless on ancient ext3).
#spark.shuffle.consolidateFiles  true
#
## Size of the in-memory buffer for each shuffle output stream, in kilobytes.  Useful for reducing seeks
#spark.shuffle.file.buffer.kb    100
#
## If set to "true", limits the amount of memory used during reduces by spilling data out to disk. This spilling threshold is specified by spark.shuffle.memoryFraction.
#spark.shuffle.spill             true
#
## Speculative job execution to avoid the straggler problem.
#spark.speculation               false
#
## How often to check for tasks to speculate, in milliseconds.
#spark.speculation.interval      100
#
#spark.speculation.quantile      0.75
#
#spark.speculation.multiplier    1.5
#
# Log the supplied SparkConf as INFO at the start of Spark context
spark.logConf                   true

# only for standalone
#spark.deploy.spreadOut          true

# only for standalone#
#spark.deploy.defaultCores       (infinite)

# spark.serializer        org.apache.spark.serializer.KryoSerializer
