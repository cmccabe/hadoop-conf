<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- WARNING: anything you put here may be overwritten by HDFS defaults!
    Still, you have to put configuration options that clients also need in
    here. -->
    <property>
      <name>fs.default.name</name>
      <value>hdfs://localhost</value>
    </property>
    <property>
      <name>hadoop.tmp.dir</name>
      <value>/h/tmp</value>
    </property>
    <property>
      <name>hadoop.log.dir</name>
      <value>/r/logs</value>
    </property>
    <!--<property>
      <name>hadoop.security.group.mapping</name>
      <value>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</value>
    </property>-->
    <property>
      <name>fs.shell.htrace.sampler.classes</name>
      <value>AlwaysSampler</value>
    </property>
    <property>
      <name>hadoop.htrace.span.receiver.classes</name>
     <value>org.apache.htrace.core.LocalFileSpanReceiver</value>
    </property>
    <property>
      <name>hadoop.htrace.htraced.rest.url</name>
      <value>http://127.0.0.1:9095/</value>
    </property>
    <property>
      <name>hadoop.htrace.local.file.span.receiver.capacity</name>
      <value>1</value>
    </property>
</configuration>
